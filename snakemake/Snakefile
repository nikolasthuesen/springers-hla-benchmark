configfile: "config.yaml"

def mem(gb=0,mb=0,kb=0,b=0):
    return gb*10**9 + mb*10**6 + kb*10**3 + b

ruleorder: download_data > index_cram #> convert_data > index_bam > measure_depth

rule all:
    input:
        # expand(output_dir + "kourami/{sample_id}.txt", sample_id = config["sample_urls"]),
        # expand(output_dir + "hisatgenotype/{sample_id}.txt", sample_id = config["sample_urls"]),
        # expand(output_dir + "hla-la/{sample_id}.txt", sample_id = config["sample_urls"]),
        # expand(output_dir + "optitype/{sample_id}.txt", sample_id = config["sample_urls"]),
        # expand(output_dir + "depth/{sample_id}.depth.mosdepth.summary.txt", sample_id = config["sample_urls"])
        expand("results/00_cram_downloads/{sample_id}.cram.crai", sample_id=config["sample_urls"])


rule download_data:
    output:
        cram = "results/00_cram_downloads/{sample_id}.cram"
    resources:
        walltime = 10000
    run:
        url = config["sample_urls"][wildcards.sample_id]
        shell("wget {url} -O {output.cram}")

rule index_cram:
    input:
        cram = rules.download_data.output.cram
    threads: 10
    resources: 
        mem = mem(gb = 40),
        walltime = 10000
    output:
        crai = "results/00_cram_downloads/{sample_id}.cram.crai",
    container:
        "https://hub.docker.com/r/staphb/samtools",
    shell:
        """
        samtools index -@4 {input.cram}
        """

# rule download_reference_genome:
#     input:
#     output:
#     shell:

# #/home/projects/cu_10148/people/nikthu/data/ref_genome_data/GRCh38_full_analysis_set_plus_decoy_hla.fa
# rule cram_2_bam:
#     input:
#         cram = rules.download_data.output.cram
#         crai = rules.index_cram.output.crai
#         ref_genome = rules.download_reference_genome
#     threads: 10
#     resources: 
#         mem = mem(gb = 40),
#         walltime = 50000
#     output:
#         bam = "results/01_bam/{sample_id}.bam",
#         bai = "results/01_bam/{sample_id}.bai",
#     shell:
#         """
#         samtools view -b -@ {resources.cores} -T {input.ref_genome} -o - {input.cram} | samtools sort --threads {resources.cores} -n - | samtools fixmate --threads {resources.cores} -m - {output.bam}
#         samtools index -@ {resources.cores} {output.bam}
#         """"

# rule index_bam:
#     input:
#         bam = data_dir + "{sample_id}.bam"
#     threads: 40
#     resources: 
#         mem = mem(gb = 120),
#         walltime = 10000
#     output:
#         bai = temp(data_dir + "{sample_id}.bam.bai"),
#     run:
#         shell(script_dir + "index_bam.sh {input.bam}")

# rule measure_depth:
#     input:
#         cram = data_dir + "cram_downloads/{sample_id}.cram",
#         crai = data_dir + "cram_downloads/{sample_id}.cram.crai"
#     threads: 10
#     resources: 
#         mem = mem(gb = 20),
#         walltime = 10000
#     output:
#         depth = output_dir + "depth/{sample_id}.depth.mosdepth.summary.txt"
#     run:
#         shell(script_dir + "measure_depth.sh {wildcards.sample_id}")


# rule submit_kourami:
#     input:
#         bam = data_dir + "{sample_id}.bam",
#         bai = data_dir + "{sample_id}.bam.bai"
#     threads: 10
#     resources: 
#         mem = mem(gb = 50),
#         walltime = 20000
#     output:
#         kourami = output_dir + "kourami/{sample_id}.txt",
#     run:
#         shell(script_dir + "tool_jobscripts/job_kourami.sh {input.bam} {wildcards.sample_id}")

# rule submit_optitype:
#     input:
#         fastq1 = data_dir + "{sample_id}.bam_reads1.fastq.gz",
#         fastq2 = data_dir + "{sample_id}.bam_reads2.fastq.gz"
#     threads: 10
#     resources: 
#         mem = mem(gb = 50),
#         walltime = 20000
#     output:
#         optitype = output_dir + "optitype/{sample_id}.txt"
#     run:
#         shell(script_dir + "tool_jobscripts/job_optitype.sh {wildcards.sample_id}")


# rule submit_hisatgenotype:
#     input:
#         fastq1 = data_dir + "{sample_id}.bam_reads1.fastq.gz",
#         fastq2 = data_dir + "{sample_id}.bam_reads2.fastq.gz"
#     threads: 10
#     resources: 
#         mem = mem(gb = 50),
#         walltime = 20000
#     output:
#         hisatgenotype = output_dir + "hisatgenotype/{sample_id}.txt"
#     run:
#         shell(script_dir + "tool_jobscripts/job_hisatgenotype.sh {wildcards.sample_id}")


# rule submit_hla_la:
#     input:
#         bam = data_dir + "{sample_id}.bam",
#         bai = data_dir + "{sample_id}.bam.bai"
#     threads: 10
#     resources: 
#         mem = mem(gb = 185),
#         walltime = 172800
#     output:
#         hla_la = output_dir + "hla-la/{sample_id}.txt"
#     run:
#         shell(script_dir + "tool_jobscripts/job_hla-la.sh {input.bam} /home/projects/cu_10148/people/nikthu/output/hla-la {wildcards.sample_id}")


